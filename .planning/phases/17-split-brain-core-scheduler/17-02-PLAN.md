---
phase: 17-split-brain-core-scheduler
plan: 02
type: execute
wave: 2
depends_on: ["17-01"]
files_modified:
  - backend/brain/exam_brain.py
  - backend/brain/routes.py
autonomous: true
requirements: [SB-03, SB-04]

must_haves:
  truths:
    - "Auditor context assembly concatenates all exams and their extracted_text"
    - "Context assembly respects 700K character limit with truncation"
    - "Auditor prompt identifies topics, tasks, and gaps (syllabus topics without summary content)"
    - "generate-roadmap route returns Auditor output (tasks, gaps, topic_map) instead of a full schedule"
    - "Auditor output is persisted in the auditor_draft column of the exams table"
    - "/brain/auditor-draft route retrieves the persisted draft"
  artifacts:
    - path: "backend/brain/exam_brain.py"
      provides: "_build_all_exam_context, _build_auditor_prompt, and Auditor-only call_split_brain"
      contains: "call_split_brain"
    - path: "backend/brain/routes.py"
      provides: "Updated generate-roadmap and new auditor-draft routes"
      contains: "auditor-draft"
  key_links:
    - from: "backend/brain/routes.py"
      to: "backend/brain/exam_brain.py"
      via: "call_split_brain invocation"
      pattern: "call_split_brain"
    - from: "backend/brain/exam_brain.py"
      to: "backend/server/database.py"
      via: "Reading extracted_text and writing auditor_draft"
      pattern: "extracted_text|auditor_draft"
---

<objective>
Implement the Knowledge Audit (Auditor) layer of the Split-Brain architecture.

Purpose: Instead of generating a schedule in one go, the system will first "audit" the study materials. It will concatenate all exam data and files, use Claude Haiku to identify study tasks and content gaps, and save this intermediate "draft" to the database. This allows the user to review the plan and address missing materials before the Strategist generates the final schedule.

Output: Updated ExamBrain with Auditor logic and updated API routes that handle the intermediate Auditor state.
</objective>

<execution_context>
@/Users/eyalatar/.claude/get-shit-done/workflows/execute-plan.md
@/Users/eyalatar/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-split-brain-core-scheduler/17-CONTEXT.md
@.planning/phases/17-split-brain-core-scheduler/17-RESEARCH.md
@.planning/phases/17-split-brain-core-scheduler/17-01-SUMMARY.md
@backend/brain/exam_brain.py
@backend/brain/routes.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Auditor Context Assembly and Prompt Building</name>
  <files>backend/brain/exam_brain.py</files>
  <action>
Implement the foundation for the Auditor call in `ExamBrain`:

1. **_build_all_exam_context(self) -> str**:
   - Iterate through `self.exams`.
   - For each exam, fetch all associated `exam_files` (syllabus, summary, sample_exam, etc.) from the DB.
   - Concatenate their `extracted_text` with clear headers (e.g., `[SYLLABUS: file.pdf]`).
   - If no `extracted_text` exists (legacy), fall back to `parsed_context`.
   - Implement **Truncation Logic**: Use a `CHAR_LIMIT = 700000` (~175K tokens). If the total length exceeds this, truncate the content of each file proportionally or simply stop adding new content with a `[TRUNCATED]` warning.

2. **_build_auditor_prompt(self, all_exam_context: str, total_hours: float) -> str**:
   - Create the system prompt for the Auditor.
   - Requirements: Identify syllabus topics, detect GAPS (topics in syllabus but not in summaries), decompose into tasks with `focus_score` (1-10), `reasoning` (brief explanation for the score), and `dependency_id`.
   - Output format: MUST be valid JSON with `tasks`, `gaps`, and `topic_map` keys.
   - Reference the pattern provided in `17-RESEARCH.md`.

3. **_calculate_total_hours(self) -> float**:
   - Helper to sum up `days_until * neto_study_hours` for all exams to provide a global budget to the AI.
  </action>
  <verify>
Unit test or manual script calling `_build_all_exam_context` for a user with multiple exams/files. Verify headers and truncation when dummy large text is injected.
  </verify>
  <done>ExamBrain can assemble long-context strings from DB-stored text and generate the Auditor prompt.</done>
</task>

<task type="auto">
  <name>Task 2: Auditor Execution and JSON Parsing</name>
  <files>backend/brain/exam_brain.py</files>
  <action>
Implement the Auditor execution logic in `ExamBrain`:

1. **call_split_brain(self) -> dict**:
   - This replaces `analyze_all_exams`.
   - Call `_build_all_exam_context()`.
   - Call `_build_auditor_prompt()`.
   - Execute the Claude Haiku call using `self.client.messages.create`.
   - Implement robust JSON parsing: strip markdown fences (` ```json ... ``` `), handle preambles/commentary by finding the first `{` and last `}`.
   - Return the parsed dictionary containing `tasks`, `gaps`, and `topic_map`.

2. **Validation**:
   - Ensure `focus_score` is present and clamped to 1-10.
   - Ensure `reasoning` is present for each task.
   - Ensure `dependency_id` is handled correctly (null or integer).
   - Ensure each task has an `exam_id`.
  </action>
  <verify>
Run `call_split_brain` with a test set of exams and files. Print the result and verify it contains the expected keys and structured tasks (including reasoning).
  </verify>
  <done>ExamBrain successfully performs the Auditor call and returns structured analysis of tasks and gaps.</done>
</task>

<task type="auto">
  <name>Task 3: Brain Routes Integration and Persistence</name>
  <files>backend/brain/routes.py</files>
  <action>
Update the API routes to handle the new intermediate state:

1. **Update POST /brain/generate-roadmap**:
   - Switch from `brain.analyze_all_exams()` to `brain.call_split_brain()`.
   - **Crucial**: Do NOT clear the `tasks` or `schedule_blocks` tables yet. This is an intermediate step.
   - **Crucial**: Do NOT run the scheduler yet.
   - Persistence: Save the Auditor's JSON output (tasks + gaps + topic_map) into the `auditor_draft` column of the `exams` table for ALL exams belonging to the user.
   - Return the Auditor output directly to the client.

2. **Add GET /brain/auditor-draft**:
   - New endpoint that fetches the `auditor_draft` from the `exams` table for the current user.
   - Return the first non-null `auditor_draft` found for that user.
   - This allows the frontend (in next plans) to retrieve the draft if the page is refreshed.

3. **Update rollover_tasks**:
   - Ensure it is still called or aware of the new flow, though it might move to Wave 3 (Strategist). For now, keep it where it is or move it to the start of the audit if necessary.
  </action>
  <verify>
1. Call `POST /brain/generate-roadmap` via curl/Postman. Verify it returns tasks and gaps, and DOES NOT change the current schedule/tasks in the DB.
2. Verify the `auditor_draft` column in the DB is populated.
3. Call `GET /brain/auditor-draft` and verify it returns the same data.
  </verify>
  <done>The generate-roadmap route now performs the Knowledge Audit and persists the results. The system is ready for the Intermediate Review Page and the Strategist call.</done>
</task>

</tasks>

<verification>
- Auditor context includes text from all exam files
- Context truncation works for very large inputs
- Auditor call returns tasks with focus_score and dependency_id
- Gaps are identified and returned
- Auditor results are saved to auditor_draft in DB
- API returns Auditor output instead of a full schedule
</verification>

<success_criteria>
The Backend successfully implements the first half of the Split-Brain architecture. The system can now perform a "Zero-Loss Audit" of all study materials and identify gaps, persisting this state for user review.
</success_criteria>

<output>
After completion, create `.planning/phases/17-split-brain-core-scheduler/17-02-SUMMARY.md`
</output>
